- To Do
map, flatMap, reduce function, broadcast variable, accumulator,
Write a spark program to check how many times a given keyword exists in a huge text file
----------------------------------------
-Spark
Spark doesn’t provide storage layer

- Spark Properties/Configurations
The heap size refers to the memory of the Spark executor spark.executor.memory

- Map Reduce Vs Apache Spark
Map Reduce - Only batch processing
Spark - 100 times faster due to in memory processing

-RDD
myrdd = sc.parallelize([1,2,3,4,5])
an RDD is just mapping of actual data and partitions.
Resilient Distributed Datasets (RDD) is a fundamental data structure of Spark

- Yarn
Yet another resource manager

defaultParallelism - By default it is number of cores available to application.

reduce() – executes the function passed again and again until only one value is left. The function should take two arguments and return one value.
pyspark.Accumulator - A shared variable that can be accumulated, 

- Best Practices/ Optimizations
spark.conf.set("spark.microsoft.delta.optimizeWrite.enabled", "true")
spark.conf.set("spark.microsoft.delta.autoCompact.enabled", "true")
minimize data transfer/shuffling

ref - https://learn.microsoft.com/en-us/azure/databricks/optimizations/auto-optimize



To Read:
https://mkoptelov.medium.com/unit-testing-of-databricks-notebooks-54c95631125c




